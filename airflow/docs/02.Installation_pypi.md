# Airflow installation via pip

## 0.Install python env

We recommend you to install the python env with `pyenv`

```shell
# install dependencies to run the auto installation script
sudo apt install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python3-openssl git 

# download the script and run it
curl https://pyenv.run | bash

# after the above command, you need to add the env var in the output of the above command in to your .bashrc
# below is an example
export PYENV_ROOT="$HOME/.pyenv"
[[ -d $PYENV_ROOT/bin ]] && export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init -)"

# you need to reload your bashrc or restart your shell
source ~/.bashrc

# show the pyenv version
pyenv versions

# list all available version that can be installed  
pyenv install --list

# install a specific version
pyenv install 3.11.7 

# activate a python version as the current python, there are two mode: global and local
pyenv global 3.11.7
pyenv local 3.11.7

# after changing the python version, you can test it with
python -V
```

Once you have the python bin, you need to create a virtual env

```shell
# create a virtual env
python -m venv path/to/airflow_venv

# activate virtual env
source path/to/airflow_venv/bin/activate

# deactivate
deactivate
```

## 1. Install airflow via pip

Airflow has many dependencies, if we don't know which version of the installed dependencies use. The installation
is not reproducible. In order to have a reproducible installation, we need a constraint file which stores all the `dependencies and their version`
of the current installation.

You can find examples of the constraint files from the official doc. For example:
python3.8: https://raw.githubusercontent.com/apache/airflow/constraints-2.9.2/constraints-3.8.txt
python3.11: https://raw.githubusercontent.com/apache/airflow/constraints-2.9.2/constraints-3.11.txt

```shell
# if your server has internet, you can use the below command
# you need to use the right contraint file which correspond your server python version
pip install "apache-airflow[celery]==2.9.2" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.2/constraints-3.8.txt"
```

We can write a shell script to do the installation.

```shell
#!/bin/bash

# set up the home folder for airflow application, it will store all the required files of the airflow
# if not define, when you run the server, it will create the files in ~/airflow
air_root_path=/home/pengfei/opt/airflow

# set up python and airflow version
AIRFLOW_VERSION=2.9.2
PYTHON_VERSION="$(python -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')"

# add this to your bashrc
echo 'AIRFLOW_HOME=$air_root_path' >> ~/.bashrc 

export AIRFLOW_HOME=$air_root_path

# auto determine the constraint url
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"

# For example: https://raw.githubusercontent.com/apache/airflow/constraints-2.9.2/constraints-no-providers-3.8.txt
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

## 2. Run airflow in standalone mode

To test your installation, you can run the airflow server in standalone mode by using the below command.

```shell
airflow standalone
```

This command :
- initializes the database(i.e. SQlight)
- creates a root user, you will get the generated password from the output
- starts all required components(e.g. scheduler, web sever).

> In standalone mode, the executor and dag reader runs inside the scheduler.
> This mode is for dev only. 
> 
> 
If you want to run the individual parts of Airflow manually rather than using the all-in-one standalone command, you can instead run:

```shell
# populate the metadata db
airflow db migrate

# create a root user
airflow users create \
    --username admin \
    --firstname Peter \
    --lastname Parker \
    --role Admin \
    --email pengfei.liu@casd.eu

# run the web server as background process
airflow webserver --port 8080 &

# run the scheduler
airflow scheduler
```