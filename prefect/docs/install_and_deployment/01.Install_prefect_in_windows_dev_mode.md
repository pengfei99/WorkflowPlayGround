# Install prefect on windows

In this tutorial, we will install prefect on windows. This is for dev purpose, not for multiple user production deployment.

## 1. Create a virtual env

## 2. Install the prefect python package

You need to activate your virtual env before, and run the below commands in your virtual env.

```shell
# install the prefect package
python -m pip install --upgrade pip
pip install prefect

# check the installed prefect version
prefect version

# Set Prefect home and API
# You should isolate configurations per user:
# here I put my server home in my project folder. It's for dev only
setx PREFECT_HOME "C:\Users\PLIU\Documents\git\WorkflowPlayGround\prefect\server_conf"
setx PREFECT_API_URL "http://localhost:4200/api"


```

## 3. Create a PySpark Flow with Prefect

```python
from prefect import flow, task
from pyspark.sql import SparkSession

@task
def run_wordcount(source_file:str, out_file:str):
    spark = (
        SparkSession.builder
        .appName("prefect_wordcount")
        .master("local[4]")  # Limit CPU usage
        .config("spark.local.dir", "C:/Users/PLIU/Documents/git/WorkflowPlayGround/prefect/server_conf/spark_temp/pengfei")
        .getOrCreate()
    )

    df = spark.read.text(source_file)
    counts = df.rdd.flatMap(lambda x: x[0].split()) \
                   .map(lambda w: (w, 1)) \
                   .reduceByKey(lambda a, b: a + b)
    counts.toDF(["word", "count"]).write.mode("overwrite").csv(out_file)
    spark.stop()

@flow(name="spark_wordcount_flow")
def main_flow():
    src_file = "C:/Users/PLIU/Documents/git/WorkflowPlayGround/data/source/word_raw.txt"
    out_file= "C:/Users/PLIU/Documents/git/WorkflowPlayGround/data/out/wc_flow_out"
    run_wordcount(src_file,out_file)

if __name__ == "__main__":
    main_flow()
```

> To avoid access conflict for spark multiple users, we need to set up a specific **spark temp dir** per user.
> For example, we can use `spark.local.dir=C:\spark_tmp\<username>`
> 

## 4. Test your prefect flow

To run your prefect flow, the most easy way is to use `python script call`.

For example, I put the above prefect flow script in the below directory `prefect/server_conf/flows/pengfei/spark_wc_flow.py`
To run it, we can just simply call it

```shell
python prefect/server_conf/flows/pengfei/spark_wc_flow.py

# expected output
10:37:08.970 | INFO    | prefect - Starting temporary server on http://127.0.0.1:8763
See https://docs.prefect.io/v3/concepts/server#how-to-guides for more information on running a dedicated Prefect server.
10:37:12.617 | INFO    | Flow run 'impetuous-coot' - Beginning flow run 'impetuous-coot' for flow 'spark_wordcount_flow'
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/10/20 10:37:15 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/10/20 10:37:16 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/PLIU/Documents/git/WorkflowPlayGround/prefect/server_conf/spark_temp/pengfei]. Please check your configured local directories.
C:\Users\PLIU\Documents\Tool\spark\spark-3.5.2\python\lib\pyspark.zip\pyspark\shuffle.py:65: UserWarning: Please install psutil to have better support with spilling
10:37:25.903 | INFO    | Task run 'run_wordcount-12d' - Finished in state Completed()
10:37:25.942 | INFO    | Flow run 'impetuous-coot' - Finished in state Completed()
10:37:25.964 | INFO    | prefect - Stopping temporary server on http://127.0.0.1:8763
SUCCESS: The process with PID 18652 (child process of PID 11804) has been terminated.
SUCCESS: The process with PID 11804 (child process of PID 16624) has been terminated.
SUCCESS: The process with PID 16624 (child process of PID 22564) has been terminated.
```

### 4.1 Use Prefect orchestration

**There is a breaking change between Prefect 2.x and 3.x.**

To avoid confusion, in this tutorial we will only show the configuration for `Prefect 3.x`.

#### 4.1.1 Build the deployment

`Prefect 3.x` introduces the **projects** concept(instead of the older `build/apply model` in Prefect 2.x).
You now define deployments declaratively in a prefect.yaml file.

Example file structure of a prefect project:

```text
C:\projects\spark_flow\
│
├── spark_wc_flow.py
└── prefect.yaml
```

Below is an example of the `prefect.yaml`

```yaml
# prefect.yaml
name: spark_project
prefect-version: 3.4.24

deployments:
  - name: spark_wordcount
    entrypoint: spark_wc_flow.py:main_flow
    work_pool:
      name: local-pool # for local execution
      type: process
      tags: [spark, local]

```

> If the work pool doesn’t exist, create it manually: `prefect work-pool create local-pool --type process`

